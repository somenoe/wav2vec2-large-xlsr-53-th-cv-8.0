{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eb536d8",
   "metadata": {},
   "source": [
    "# Benchmarking with Our Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14de8329",
   "metadata": {},
   "source": [
    "This notebook details how you can benchmark with our test split using any function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabb23ed",
   "metadata": {},
   "source": [
    "## Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b1b0965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.rpm.sh | sudo bash\n",
    "# !sudo yum install git-lfs -y\n",
    "# !git lfs install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50869901",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install torch==1.9.0+cpu torchvision==0.10.0+cpu torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# %pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "%pip install datasets==1.11.0\n",
    "%pip install transformers==4.9.1\n",
    "%pip install jiwer\n",
    "%pip install ipywidgets\n",
    "%pip install pythainlp==2.3.1\n",
    "%pip install pydub\n",
    "%pip install SpeechRecognition\n",
    "%pip install azure-cognitiveservices-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c4dd5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import (\n",
    "    load_dataset, \n",
    "    load_from_disk,\n",
    "    load_metric,)\n",
    "from datasets.filesystems import S3FileSystem\n",
    "from transformers import (\n",
    "    Wav2Vec2CTCTokenizer, \n",
    "    Wav2Vec2FeatureExtractor,\n",
    "    Wav2Vec2Processor,\n",
    "    Wav2Vec2ForCTC,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "import torch\n",
    "import torchaudio\n",
    "import re\n",
    "import json\n",
    "from pythainlp.tokenize import word_tokenize, syllable_tokenize\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353a8b5a",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615a1d6f",
   "metadata": {},
   "source": [
    "We download the whole Common Voice 7.0 even though we will use only our test split for benchmarking. We also copy `train_cleaned.tsv`, `dev_cleaned.tsv`, and `test_cleaned.tsv` for our cleaned and resampled splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d058022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://voice-prod-bundler-ee1969a6ce8178826482b88e843c335139bd3fb4.s3.amazonaws.com/cv-corpus-7.0-2021-07-21/cv-corpus-7.0-2021-07-21-th.tar.gz\n",
    "# !tar -xvf cv-corpus-7.0-2021-07-21-th.tar.gz --no-same-owner\n",
    "# !mv cv-corpus-7.0-2021-07-21-th ../data\n",
    "# !cp train_cleaned.tsv dev_cleaned.tsv test_cleaned.tsv ../data/cv-corpus-7.0-2021-07-21-th/th"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8cde15",
   "metadata": {},
   "source": [
    "## Load Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "15cc454c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset common_voice (/home/ec2-user/.cache/huggingface/datasets/common_voice/th/7.0.0/14bf435a174687b310ed94f56abf0198f6cc7efb5a5d945c22c83113eab67701)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['path', 'sentence'],\n",
       "    num_rows: 2502\n",
       "})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = load_dataset(\"../scripts/th_common_voice_70.py\", \"th\", split=\"test\")\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c85ecfc",
   "metadata": {},
   "source": [
    "## Load Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a913eca5",
   "metadata": {},
   "source": [
    "We use WER with words tokenized by PyThaiNLP 2.3.1 and CER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "39a93c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.tokenize import word_tokenize\n",
    "\n",
    "wer_metric = load_metric(\"wer\")\n",
    "cer_metric = load_metric(\"cer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d23c7b",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "09a6f23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ec2-user/.cache/huggingface/datasets/common_voice/th/7.0.0/14bf435a174687b310ed94f56abf0198f6cc7efb5a5d945c22c83113eab67701/cache-b12df0a78d616663.arrow\n"
     ]
    }
   ],
   "source": [
    "def speech_file_to_array_fn(batch, \n",
    "                            text_col=\"sentence\", \n",
    "                            fname_col=\"path\",\n",
    "                            resampling_to=16000):\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[fname_col])\n",
    "    resampler=torchaudio.transforms.Resample(sampling_rate, resampling_to)\n",
    "    batch[\"speech\"] = resampler(speech_array)[0].numpy()\n",
    "    batch[\"sampling_rate\"] = resampling_to\n",
    "    batch[\"target_text\"] = batch[text_col]\n",
    "    return batch\n",
    "\n",
    "test_dataset = test_dataset.map(speech_file_to_array_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee9f693",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96495ed3",
   "metadata": {},
   "source": [
    "### Convert to `.wav` for Some APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47573bd0",
   "metadata": {},
   "source": [
    "We need to convert the `mp3` files to `wav`. Install `ffmpeg and ffprobe`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e821159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo su -\n",
    "# mkdir -v -p /usr/local/bin/ffmpeg\n",
    "# cd /usr/local/bin/ffmpeg\n",
    "# wget https://johnvansickle.com/ffmpeg/releases/ffmpeg-release-i686-static.tar.xz\n",
    "# tar -v -xf ffmpeg-release-i686-static.tar.xz --strip-components=1\n",
    "# rm -v -f ffmpeg-release-i686-static.tar.xz\n",
    "# ln -snf /usr/local/bin/ffmpeg/ffmpeg /usr/bin/ffmpeg\n",
    "# ln -snf /usr/local/bin/ffmpeg/ffprobe /usr/bin/ffpropbe\n",
    "# exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "15b9a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def mp3_to_wav(example):\n",
    "    example['path_wav'] = (example['path'][:-3] + 'wav').replace('clips','clips_wav')\n",
    "    sound = AudioSegment.from_mp3(example['path'])\n",
    "    sound.export(example['path_wav'], format=\"wav\")\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "77d88113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ec2-user/.cache/huggingface/datasets/common_voice/th/7.0.0/14bf435a174687b310ed94f56abf0198f6cc7efb5a5d945c22c83113eab67701/cache-1b78b0456d5d1b4f.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['path', 'sentence', 'speech', 'sampling_rate', 'target_text', 'path_wav'],\n",
       "    num_rows: 2502\n",
       "})"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = test_dataset.map(mp3_to_wav)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e980a28",
   "metadata": {},
   "source": [
    "### [Google Web Speech API](https://w3c.github.io/speech-api/speechapi.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a7a2d64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'และเขาก็สัมผัสดีบุก'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "def evalute_example(fname):\n",
    "    with sr.AudioFile(fname) as source:\n",
    "        audio_text = r.listen(source)\n",
    "    text = r.recognize_google(audio_text, language = \"th-TH\")\n",
    "    return text\n",
    "        \n",
    "evalute_example(test_dataset[0]['path_wav'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedaf53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3fb816b98ad403ab25c38a91af62fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = []\n",
    "for i in tqdm(test_dataset):\n",
    "    try:\n",
    "        pred = evalute_example(i['path_wav']).replace(' ','')\n",
    "    except:\n",
    "        pred = ''\n",
    "    d = {'sentence': i['sentence'].replace(' ',''), \n",
    "         'pred_sentence': pred}\n",
    "    d['sentence_tok'] = ' '.join(word_tokenize(d['sentence']))\n",
    "    d['pred_sentence_tok'] = ' '.join(word_tokenize(d['pred_sentence']))\n",
    "    ds.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1f837ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>pred_sentence</th>\n",
       "      <th>sentence_tok</th>\n",
       "      <th>pred_sentence_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>และเขาก็สัมผัสดีบุก</td>\n",
       "      <td>และเขาก็สัมผัสดีบุก</td>\n",
       "      <td>และ เขา ก็ สัมผัส ดีบุก</td>\n",
       "      <td>และ เขา ก็ สัมผัส ดีบุก</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>คุณสามารถรับทราบเมื่อข้อความนี้ถูกอ่านแล้ว</td>\n",
       "      <td>คุณสามารถรับทราบข้อความนี้ถูกอ่านแล้ว</td>\n",
       "      <td>คุณ สามารถ รับทราบ เมื่อ ข้อความ นี้ ถูก อ่าน ...</td>\n",
       "      <td>คุณ สามารถ รับทราบ ข้อความ นี้ ถูก อ่าน แล้ว</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>คืนนี้ฉันต้องทำให้ได้เธอพูดกับตัวเองฉันต้องทำใ...</td>\n",
       "      <td>คืนนี้ฉันต้องทำให้ได้เธอพูดกับตัวเองฉันต้องทำใ...</td>\n",
       "      <td>คืนนี้ ฉัน ต้อง ทำ ให้ได้ เธอ พูด กับ ตัวเอง ฉ...</td>\n",
       "      <td>คืนนี้ ฉัน ต้อง ทำ ให้ได้ เธอ พูด กับ ตัวเอง ฉ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>การทำเช่นนี้จะทำให้แผ่นถ่ายภาพเกิดแสงฟลูออเรสเ...</td>\n",
       "      <td>การทำเช่นนี้จะทำให้แผ่นถ่ายภาพเกิดแสงตัวartists</td>\n",
       "      <td>การ ทำ เช่นนี้ จะ ทำให้ แผ่น ถ่ายภาพ เกิด แสง ...</td>\n",
       "      <td>การ ทำ เช่นนี้ จะ ทำให้ แผ่น ถ่ายภาพ เกิด แสง ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ผู้ปกครองของฉันไม่สนใจความเห็นนี้อย่างละเอียดอ...</td>\n",
       "      <td>ผู้ปกครองของฉันไม่สนใจความเห็นนี้อย่างละเอียดอ...</td>\n",
       "      <td>ผู้ปกครอง ของ ฉัน ไม่ สนใจ ความเห็น นี้ อย่าง ...</td>\n",
       "      <td>ผู้ปกครอง ของ ฉัน ไม่ สนใจ ความเห็น นี้ อย่าง ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>ใครสนใจไปเรียนได้ฟรีวันละชั่วโมงสัปดาห์เดียวก็จบ</td>\n",
       "      <td>ใครสนใจจะเรียนได้ฟรีวันละชั่วโมงสัปดาห์เดียวก็จบ</td>\n",
       "      <td>ใคร สนใจ ไป เรียน ได้ ฟรี วัน ละ ชั่วโมง สัปดา...</td>\n",
       "      <td>ใคร สนใจ จะ เรียน ได้ ฟรี วัน ละ ชั่วโมง สัปดา...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>หรือในกรณีตั้งครรภ์เมื่ออายุเกิน</td>\n",
       "      <td>หรือในกรณีตั้งครรภ์เมื่ออายุเกิน</td>\n",
       "      <td>หรือ ใน กรณี ตั้งครรภ์ เมื่อ อายุ เกิน</td>\n",
       "      <td>หรือ ใน กรณี ตั้งครรภ์ เมื่อ อายุ เกิน</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>ก่อนสเต็ปนั้น</td>\n",
       "      <td>ก่อนสเต็ปนั้น</td>\n",
       "      <td>ก่อน สเต็ป นั้น</td>\n",
       "      <td>ก่อน สเต็ป นั้น</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>ถ้าจะแบนมันต้องชัดว่าคำพูดจะนำไปสู่เหตุการณ์พว...</td>\n",
       "      <td>ถ้าจะแบนมันต้องชัดว่าคำพูดจะนำไปสู่เหตุการณ์พว...</td>\n",
       "      <td>ถ้า จะ แบน มัน ต้อง ชัด ว่า คำพูด จะ นำไปสู่ เ...</td>\n",
       "      <td>ถ้า จะ แบน มัน ต้อง ชัด ว่า คำพูด จะ นำไปสู่ เ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>เขาก็เปิดดังเท่ากันน่ะ</td>\n",
       "      <td>เขาก็เปิดดังเท่ากันน่ะ</td>\n",
       "      <td>เขา ก็ เปิด ดัง เท่ากัน น่ะ</td>\n",
       "      <td>เขา ก็ เปิด ดัง เท่ากัน น่ะ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2502 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  \\\n",
       "0                                   และเขาก็สัมผัสดีบุก   \n",
       "1            คุณสามารถรับทราบเมื่อข้อความนี้ถูกอ่านแล้ว   \n",
       "2     คืนนี้ฉันต้องทำให้ได้เธอพูดกับตัวเองฉันต้องทำใ...   \n",
       "3     การทำเช่นนี้จะทำให้แผ่นถ่ายภาพเกิดแสงฟลูออเรสเ...   \n",
       "4     ผู้ปกครองของฉันไม่สนใจความเห็นนี้อย่างละเอียดอ...   \n",
       "...                                                 ...   \n",
       "2497   ใครสนใจไปเรียนได้ฟรีวันละชั่วโมงสัปดาห์เดียวก็จบ   \n",
       "2498                   หรือในกรณีตั้งครรภ์เมื่ออายุเกิน   \n",
       "2499                                      ก่อนสเต็ปนั้น   \n",
       "2500  ถ้าจะแบนมันต้องชัดว่าคำพูดจะนำไปสู่เหตุการณ์พว...   \n",
       "2501                             เขาก็เปิดดังเท่ากันน่ะ   \n",
       "\n",
       "                                          pred_sentence  \\\n",
       "0                                   และเขาก็สัมผัสดีบุก   \n",
       "1                 คุณสามารถรับทราบข้อความนี้ถูกอ่านแล้ว   \n",
       "2     คืนนี้ฉันต้องทำให้ได้เธอพูดกับตัวเองฉันต้องทำใ...   \n",
       "3       การทำเช่นนี้จะทำให้แผ่นถ่ายภาพเกิดแสงตัวartists   \n",
       "4     ผู้ปกครองของฉันไม่สนใจความเห็นนี้อย่างละเอียดอ...   \n",
       "...                                                 ...   \n",
       "2497   ใครสนใจจะเรียนได้ฟรีวันละชั่วโมงสัปดาห์เดียวก็จบ   \n",
       "2498                   หรือในกรณีตั้งครรภ์เมื่ออายุเกิน   \n",
       "2499                                      ก่อนสเต็ปนั้น   \n",
       "2500  ถ้าจะแบนมันต้องชัดว่าคำพูดจะนำไปสู่เหตุการณ์พว...   \n",
       "2501                             เขาก็เปิดดังเท่ากันน่ะ   \n",
       "\n",
       "                                           sentence_tok  \\\n",
       "0                               และ เขา ก็ สัมผัส ดีบุก   \n",
       "1     คุณ สามารถ รับทราบ เมื่อ ข้อความ นี้ ถูก อ่าน ...   \n",
       "2     คืนนี้ ฉัน ต้อง ทำ ให้ได้ เธอ พูด กับ ตัวเอง ฉ...   \n",
       "3     การ ทำ เช่นนี้ จะ ทำให้ แผ่น ถ่ายภาพ เกิด แสง ...   \n",
       "4     ผู้ปกครอง ของ ฉัน ไม่ สนใจ ความเห็น นี้ อย่าง ...   \n",
       "...                                                 ...   \n",
       "2497  ใคร สนใจ ไป เรียน ได้ ฟรี วัน ละ ชั่วโมง สัปดา...   \n",
       "2498             หรือ ใน กรณี ตั้งครรภ์ เมื่อ อายุ เกิน   \n",
       "2499                                    ก่อน สเต็ป นั้น   \n",
       "2500  ถ้า จะ แบน มัน ต้อง ชัด ว่า คำพูด จะ นำไปสู่ เ...   \n",
       "2501                        เขา ก็ เปิด ดัง เท่ากัน น่ะ   \n",
       "\n",
       "                                      pred_sentence_tok  \n",
       "0                               และ เขา ก็ สัมผัส ดีบุก  \n",
       "1          คุณ สามารถ รับทราบ ข้อความ นี้ ถูก อ่าน แล้ว  \n",
       "2     คืนนี้ ฉัน ต้อง ทำ ให้ได้ เธอ พูด กับ ตัวเอง ฉ...  \n",
       "3     การ ทำ เช่นนี้ จะ ทำให้ แผ่น ถ่ายภาพ เกิด แสง ...  \n",
       "4     ผู้ปกครอง ของ ฉัน ไม่ สนใจ ความเห็น นี้ อย่าง ...  \n",
       "...                                                 ...  \n",
       "2497  ใคร สนใจ จะ เรียน ได้ ฟรี วัน ละ ชั่วโมง สัปดา...  \n",
       "2498             หรือ ใน กรณี ตั้งครรภ์ เมื่อ อายุ เกิน  \n",
       "2499                                    ก่อน สเต็ป นั้น  \n",
       "2500  ถ้า จะ แบน มัน ต้อง ชัด ว่า คำพูด จะ นำไปสู่ เ...  \n",
       "2501                        เขา ก็ เปิด ดัง เท่ากัน น่ะ  \n",
       "\n",
       "[2502 rows x 4 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result_df = pd.DataFrame(ds)\n",
    "# result_df.to_csv('artifacts/result_google.csv',index=False)\n",
    "\n",
    "result_df = pd.read_csv('artifacts/result_google.csv').fillna('')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "abf2f24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1371123407540857"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wer\n",
    "wer_metric.compute(predictions=result_df.pred_sentence_tok,references=result_df.sentence_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1c961fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07357340720221607"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cer\n",
    "cer_metric.compute(predictions=result_df.pred_sentence,references=result_df.sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4855097b",
   "metadata": {},
   "source": [
    "### [Microsoft Bing Speech API](https://azure.microsoft.com/en-us/services/cognitive-services/speech/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "10884ee5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Runtime exception",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-712c2d67bc59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m speech_config = speechsdk.SpeechConfig(subscription=\"\", \n\u001b[0;32m----> 4\u001b[0;31m                                        region=\"\")\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# speech_config.speech_recognition_language = \"th-TH\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/azure/cognitiveservices/speech/speech.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, subscription, region, endpoint, host, auth_token, speech_recognition_language)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         self._impl = self._get_impl(impl.SpeechConfig, subscription, region, endpoint, host, auth_token,\n\u001b[0;32m---> 62\u001b[0;31m                 speech_recognition_language)\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_property\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperty_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPropertyId\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/azure/cognitiveservices/speech/speech.py\u001b[0m in \u001b[0;36m_get_impl\u001b[0;34m(config_type, subscription, region, endpoint, host, auth_token, speech_recognition_language)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mendpoint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhost\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mauth_token\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneric_error_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0m_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_subscription\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubscription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mregion\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mauth_token\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mendpoint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhost\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msubscription\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Runtime exception"
     ]
    }
   ],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "speech_config = speechsdk.SpeechConfig(subscription=\"\", \n",
    "                                       region=\"\")\n",
    "# speech_config.speech_recognition_language = \"th-TH\"\n",
    "\n",
    "audio_input = speechsdk.AudioConfig(filename=test_dataset[100]['path_wav'])\n",
    "speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_input)\n",
    "result = speech_recognizer.recognize_once_async().get()\n",
    "result.text, result.error_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c39934",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = []\n",
    "for i in tqdm(test_dataset):\n",
    "    try:\n",
    "        pred = evalute_example(i['path_wav']).replace(' ','')\n",
    "    except:\n",
    "        pred = ''\n",
    "    d = {'sentence': i['sentence'].replace(' ',''), \n",
    "         'pred_sentence': pred}\n",
    "    d['sentence_tok'] = ' '.join(word_tokenize(d['sentence']))\n",
    "    d['pred_sentence_tok'] = ' '.join(word_tokenize(d['pred_sentence']))\n",
    "    ds.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf725e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(ds)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6ada66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wer\n",
    "wer_metric.compute(predictions=result_df.pred_sentence_tok,references=result_df.sentence_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b572cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cer\n",
    "cer_metric.compute(predictions=result_df.pred_sentence,references=result_df.sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e052c9",
   "metadata": {},
   "source": [
    "### [NECTEC AI for Thai Partii API](https://aiforthai.in.th/aiplatform/#/speechtotext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "db1f9bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result = {\"status\":\"False\",\"message\":\"No asr result\",\"inputfilename\":\"\",\"outputfilename\":\"\"}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    " \n",
    "url = \"https://api.aiforthai.in.th/partii-webapi\"\n",
    " \n",
    "fname = test_dataset[0]['path_wav']\n",
    "files = {'wavfile': (fname, open(fname, 'rb'), 'audio/wav')}\n",
    " \n",
    "headers = {\n",
    "    'Apikey': \"\",\n",
    "    'Cache-Control': \"no-cache\",\n",
    "    'Connection': \"keep-alive\",\n",
    "    }\n",
    " \n",
    "param = {\"outputlevel\":\"--uttlevel\",\"outputformat\":\"--txt\"}\n",
    " \n",
    "response = requests.request(\"POST\", url, headers=headers, files=files, data=param)\n",
    " \n",
    "print(\"Result = \" + response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8c3b8efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/cv-corpus-7.0-2021-07-21/th/clips_wav/common_voice_th_25656242.wav'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301f0664",
   "metadata": {},
   "source": [
    "### `wav2vec2` Models from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29b7bfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(\"airesearch/wav2vec2-large-xlsr-53-th\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"airesearch/wav2vec2-large-xlsr-53-th\")\n",
    "\n",
    "def evaluate(batch):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    inputs = processor(batch[\"speech\"], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs.input_values.to(device),).logits\n",
    "\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    batch[\"pred_sentence\"] = processor.batch_decode(pred_ids)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f733855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes quite a long time on CPU\n",
    "result = test_dataset.map(evaluate, batched=True, batch_size=8)\n",
    "result_df = pd.DataFrame({'sentence':result['sentence'], 'pred_sentence_tok': result['pred_sentence']})\n",
    "result_df['sentence_tok'] = result_df.sentence.map(lambda x: ' '.join(word_tokenize(x)))\n",
    "result_df['pred_sentence'] = result_df.pred_sentence_tok.map(lambda x: ''.join(x.split()))\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc359a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wer\n",
    "wer_metric.compute(predictions=result_df.pred_sentence_tok,references=result_df.sentence_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a22ea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cer\n",
    "cer_metric.compute(predictions=result_df.pred_sentence,references=result_df.sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p36",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
